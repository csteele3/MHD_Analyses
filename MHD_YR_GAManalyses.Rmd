---
title: "GAM_MHD"
author: "Christen"
date: "March 25, 2020"
output:
  html_document:
    df_print: paged
---

GAM Work with Monarch Health Data



*Overall Research Objectives*
1.	Determine how OE infection prevalence changes seasonally (within a year) and across years in the southeastern U.S. 

2.	Determine where OE infection prevalence is most prevalent within each year and how the spatial patterns of infection have changed over time? 

3.	Determine whether climatic variables are correlated with the spatial and temporal changes in OE infection prevalence in the southeastern U.S.

*Why use a GAM?*
We do not expect the patterns in disease prevalence as described by our predictor variables to be linear. For example, infection prevalence may experience increases during periods of warm weather such as in late fall and early spring, while mid winter low temperatures may result in a decline in infection prevalence as population density and therefore transmission potential declines. Graphs of the dataset are provided below for visual inspection of the linear or non-linear trends.  

*Dataset*
```{r}
#The below dataset should be used to examine winter OE data  
#wdata <- read.csv("./data/MHD_WD.csv", colClasses = c("Pop_density_CAT" = "factor", "Hardiness2" = "factor", "Infection_Severity" = "factor", "Month"= "factor", "Year"= "factor"))

#The dataset below should be used to examine annual OE data
data<- read.csv("./data/YR_MHD.csv")

summary (data)
```


*Exploration of the Data through Graphing*
Graph the relationship between infection and day of year to visually inspect the relationship for linearity. 
From this figure it is hard to discern any clear pattern. There seems to be a mostly random distribution of infection prevalence across all year (by day of year). #Note: Day 200 is mid-July 
```{r}
#Convert variables into different forms for graphing purposes
data$Day_Year<-as.factor(data$Day_Year)
data$Infection<-as.numeric(data$Infection)

#Calculate the probability of infection on each day of year 
library(plyr)
r2<-ddply(data,.(Day_Year), summarize, mean=mean(Infection))
r3<- (r2$mean)
r2$r3 <- r3

library(ggplot2)
ggplot(data=r2, aes(x=as.numeric(Day_Year),shape =  Year.Sampled, r3))+geom_point() + geom_smooth()
```

Graph the relationship between infection and year to visually inspect the relationship for linearity. 
```{r}
#Convert variables into different forms for graphing purposes
##data$Season<-revalue(data$Season, c("11_12"="1", "12_13"="2", "13_14"="3", "14_15"="4", "15_16"="5", "16_17"="6", "17_18"="7"))

data$Year.Sampled<-as.factor(data$Year.Sampled)
data$Infection<-as.numeric(data$Infection)


#Calculate the probability of infection on each day of year 
library(plyr)
s1<-ddply(data,.(Year.Sampled), summarize, mean=mean(Infection))
s2<- (s1$mean)
s1$s2 <- s2

#Plot 
plot(as.numeric(s1$Year.Sampled), s1$
       s2, xlab = "Year", ylab = "Probability of Infection", type='o')
```


Graph the spatial distribution of the data.  
```{r}
library("maps")
library("dplyr")
library("ggplot2")

states <- map_data("state")

se_map <- subset(states, region %in% c("florida", "georgia", "louisiana", "alabama", "mississippi", "texas", "south carolina", "oklahoma", "arkansas", "north carolina", "tennessee", "virginia", "kentucky", "west virginia", "missouri", "illinois", "kansas"))

gg<-ggplot() + 
  geom_polygon(data=se_map,aes(x=long,y=lat,group=group), fill="grey", colour = "white")+
   geom_point(data=data, aes(x=Longitude, y=Latitude, color = factor(Infection)), position = "jitter", size=1)+
  scale_colour_manual(values = c("1"="chocolate3", "0"= "cyan"))+
 
 # geom_point(data=data, aes(x=Longitude, y=Latitude),size=1, colour = "black")
  coord_map(xlim = c(-98.5, -75),ylim = c(24, 37))+
   xlab("Longitude") + ylab("Latitude")

  gg + theme(panel.background = element_rect(fill = "skyblue3",
                                colour = "skyblue3"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())
```


*Objective 1: Analyzing the Temporal Patterns in OE Infection Prevalence in the SE*
  
  *Hypothesis 1: Within Year*
If OE infection prevalence is primarily driven by reproductive behavior and breeding is  occurring year-round in the southeast, then  OE infection prevalence may remain high, showing little correlation with day of year. 

  *Hypothesis 2: Between Years*
  If the population of winterbreeding monarchs in the southeastern US is growing (and therefore becoming more dense), we expect that OE infection prevalence may increase with year as increased monarch density leads to higher rates of transmission.
  
*Model Construction*
This model is designed to characterize temporal infection patterns in the southeast by including day of year, year and an interaction of these two terms in a single model. 

Details on the model:
1. Why "ti"?
  Tensor product smooths are used to model interactions between variables that have different natural scales. They multiply the smooth terms of one variable by the factor levels of the other. 

2. Why "by"?
  "By" variables are used for constructing "varying coefficient models" and for letting smooths interact with parametric terms. In this case our smooth is the Day_Year variable and the Season term is the parametric term (and a factor). 
The interaction between two parametric terms would use the : or * connotation, but smooth interactions cannot. "By" generates an indicator vector for each level of a factor  unless the factor is ordered. If it is ordered then a different smooth is generated for each fator level (except the first level). 


3. Why k=6? 
The term k is also referred to as "knots". These are the natural breaks in the basis functions that make up the "basis" or "smooth function" or "spline". Where the knots break along the spline is usually defined by quantiles. K is usually the max number of degrees of freedom allowed for a smooth term in the model. K in the models will always =  (max degrees of freedom - 1). In this case 

4. Why "family=binomial"? 
The response variable is either 0 (uninfected) or 1 (infected), this we have 2 curves for our response variable distribution and this requires that the model be fit with a binomial family distribution. 

5. Why is "Season" parametric?


6. Why is Volunteer "bs=re"? 
In order to include Volunteer as a random effect, we tell the model to use the random effect basis function to model this variable. This method only applies to mcgv, as a different method is used for gamm. 

7. Why REML? 

8. Should I be using a different basis function? Cubic? 

```{r eval, = FALSE if exists (gam_modIF.Rdata) }
require(mgcv)

###Make sure each variable is in the correct format 
data$Day_Year<-as.numeric(data$Day_Year)
data$Year.Sampled<-as.numeric(data$Year.Sampled)
data$Infection<-as.factor(data$Infection)

gam_modTIME <- gam(Infection ~  s(Day_Year, bs = "cc") + s(Year.Sampled,  k = 8) + ti(Day_Year, bs = "cc", by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)

save(gam_modTIME, file="gam_modII.Rdata")

summary(gam_modTIME)



```



The following models are the different iterations that eventually led to the final model selected above. They change terms in the model from smooth to linear or investigate the way the interaction term is used. 
```{r eval, = FALSE if exists (gam_modIF.Rdata) }

# #gam_mod: Model with Year as a linear effect
# gam_mod <- gam(Infection ~  Year.Sampled + ti(Day_Year, by = Year.Sampled, k =6) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)
# 
# summary(gam_mod) 
# save(gam_mod, file="gam_mod.Rdata")
# 
# 
# ###gam_modSS: Fit model with Year smoothed (numeric)
# 
# data$Year.Sampled<-as.numeric(data$Year.Sampled)
# 
# gam_modSS <- gam(Infection ~  s(Year.Sampled, k = 8) + ti(Day_Year, by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)
# 
# summary(gam_modSS)
# save(gam_modSS, file="gam_modSS.Rdata")
# 
# 
# ###Fit model with Day_Year as an added  individual effect with both day_year and year smoothed
# 
# #Running Both as numeric variables
# data$Year.Sampled<-as.numeric(data$Year.Sampled)
# data$Day_Year<-as.numeric(data$Day_Year)
# 
# gam_modIY <- gam(Infection ~  s(Day_Year) + s(Year.Sampled, k = 8) + ti(Day_Year, by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)
# 
# save(gam_modIY, file="gam_modIY.Rdata")
# summary(gam_modIY)
# 
# 
# ###Fit model with Day_Year as an added  individual effect with year as a factor
# data$Year.Sampled<-as.factor(data$Year.Sampled)
# data$Day_Year<-as.numeric(data$Day_Year)
# 
# 
# gam_modIF <- gam(Infection ~  s(Day_Year) + Year.Sampled + ti(Day_Year, by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)
# 
# save(gam_modIF, file="gam_modIF.Rdata")
# summary(gam_modIF)
# 
# 
# #WHen comparing all 4 models:
# #gam_modIF = 12266.17
# #gam_modIY = 12813.5. 
# #gam_mod =   12317.86
# #gam_modSS = 12859.28
# AIC(gam_modIY, gam_modIF, gam_mod, gam_modSS)
# 
# 
# #Model without "by" as the interaction term# 
# gam_modNoby <- gam(Infection ~  s(Day_Year, bs = "cc") + s(Year.Sampled,  k = 8) + ti(Day_Year, bs = "cc", by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)
# 
# save(gam_modNoby, file="gam_modNoby.Rdata")
# 
# AIC(gam_modIY, gam_modIF, gam_mod, gam_modSS, gam_modII)

#Could it be that the AIC value is higher when year is a factor because it is more closely fitting the data, but it is not answering the question we have about Year, which is how does infection change OVER TIME? WIth year as a factor, the question seems to be how does infection change from year to year or within a single year. 

# gam_modIY	264.3734	14116.17		
# gam_modIF	278.3352	13646.39		
# gam_mod	267.6086	  12317.86		
# gam_modSS	242.2135	12859.28		
# gam_modII	295.0423	13675.55	
#with te added: gam_modII	292.4565	13674.03	(without "by")
#with Day_Year as cyclic: 13671.31 (without "by")
#with Day as cyclic and Year as cubic: 13671.31 (so not needed) (without "by")
# "by" added back in 14281.25
#remove "Te"

# #Model with only interaction term for contour plot#
# gam_modCC <- gam(Infection ~   ti(Day_Year, by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)

```


*Summarize output of model*
```{r}
summary.gam(gam_modTIME) 

#For standard deviations and confidence intervals 
gam.vcomp(gam_modTIME)
```
Key points from model output: 

The model output summary tells us that the additive temporal variables explain 42.5% of the deviance.We also can convert the outputs from the model to actual probabilities because the GAM model uses a log-odds scale for estimating outputs. After converting the intercept estimate below we find that the model predicts a 44.1% chance of infection overall. 
```{r}
plogis(-0.2373)
```


*Checking the Model*
```{r}
#gam.check(gam_modTIME)

#gam.check does not seem to be the best method for visualizing logistic models

library(arm)

binnedplot(fitted(gam_modTIME), 
           residuals(gam_modTIME, type = "response"), 
           nclass = NULL, 
           xlab = "Expected Values", 
           ylab = "Average residual", 
           main = "S Year", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")
```


*Plot the results of the temporal model* 
Plots of the partial effects of the interaction fo Day_Year and Season for each level of Season. 

```{r}
require(mgcViz)
require(mgcv)

#Year.Sampled = c("2011-2012", "2012-2013", "2013-2014", "2014-2015", "2015-2016", "2016-2017", "2017-2018")
#axis(, at=1:8, xaxp=letters[2011:2018])

#Version1
plot(gam_modII, pages = 1,  trans = plogis,
     shift = coef(gam_modIY)[1], seWithMean = TRUE, rug = FALSE, shade = TRUE, shade.col = "lightgrey")

#Version2
b <- getViz(gam_modII, trans = plogis)

print(plot(b, allTerms = T))
```

Visualization of the interaction between Year and Day_Year in a 3D plot. 
```{r}

vis.gam(gam_modII, n.grid = 50, theta = 400, phi = 20, ylab = "Day of Year", xlab = "Year", zlab = "",
        ticktype = "detailed", color = "terrain", main = "Interaction between day of year and season")



##theta= rotates the view around horizontally 
##phi = rotates the view vertically 
##n.grid =  controls the number of grid boxes
##z scale = GAM model predictions 

```

Visualization of the interaction between Year and Day_Year in a contour plot.
```{r}
require(mgcv)

vis.gam(gam_modTIME, view=c("Day_Year","Year.Sampled"),plot.type="contour", color = "terrain", contour.col = "black") 

#The contour lines represent points of equal predicted values, and they are labeled. The dotted lines show uncertainty in prediction; they represent how contour lines would move if predictions were one standard error higher or lower.

#Run a model without an interaction to help understand the contour plot 
  #gam_modNI <- gam(Infection ~  s(Day_Year) + s(Year.Sampled, k = 8)  + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)
  #save(gam_modNI, file="gam_modNI.Rdata" )
  #vis.gam(plog, view=c("Day_Year","Year.Sampled"),plot.type="contour", color = "terrain", contour.col = "yellow") 


devtools::install_github('gavinsimpson/gratia')
library('gratia')
mod <- gam(y ~ s(x, z, k = 30), data = dat$data, method = "REML")

mod <- gam(Infection ~   ti(Day_Year, bs = "cc", by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)


draw(gam_modII)



```


Summary of plot results: 

*Spatio-temporal Model Example* 

Joint models of space and time. 

Should an interaction between space and time be included? This is compared here and the interaction is found to be significant and produces a significantly lower AIC value compared to the non-interaction term model. 
```{r}
data$Year.Sampled<-as.numeric(data$Year.Sampled)


#First, run a model without an interaction between space and time as done in the example. By comparing this model to the model with a space-tie interaction, we will be able to determine the relative importance of the interaction term. 

STno = gam(Infection~ s(Longitude_city,Latitude_city) + s(Year.Sampled, k = 8) + s(Volunteer, bs="re"),
                          data=data,family=binomial,method="REML")

save(STno, file="STno.Rdata")
summary(STno)
plot(STno,scheme=2)


#Now run the model with the interaction term 

STyes = gam(Infection~ s(Longitude,Latitude) + s(Year.Sampled, k = 8)+ ti(Longitude, Latitude, Year.Sampled, d=c(2,1)) + s(Volunteer, bs="re"),
                          data=data,family=binomial,method="REML")
save(STyes, file="STyes.Rdata")
summary(STyes)
plot(STyes,scheme=2)

load("STyes.Rdata")
AIC(STyes)


```
WHile including the interaction term improves the fit of the model, it doesnt make it easy to determine where we are seeing 1) OE hotspots within each year 2) the greatest change in hotspots over time. 

We will next use the "predict" function from mgcv to better visualize the output of the STyes model. 


Graphing of space-time interactions 


We need to select a volunteer whose observations represent the average infection prevalence found by all volunteers. To do this, we will first determine the average infection prevalence per volunteer and then select the volunteer whose average is closest to this number. 
```{r}
#First use plyr to calculate the average per volunteer 
library(plyr)
r2<-ddply(data,.(Volunteer), summarize, Avg=mean(Infection))
r2
#We now have a table r2, with the average infection prevalence per volunteer for all 269 volunteers 
```

We can visualize the distribution of infection prevalence per volunteer. 
```{r}
library(ggplot2)
ggplot(data=r2, aes(x=as.factor(Volunteer), Avg)) + geom_point()+ geom_smooth()

hist(r2$Avg)
```
Next we summarize the r2 dataframe to determine the overall mean per volunteer. 
```{r}
summary(r2)

#The mean in 0.4681
```
Select the volunteers with an average closest to the average of 0.4681
```{r}

Average_Volunteers <- r2[r2$Avg >= 0.4 & r2$Avg < 0.5, ]
Average_Volunteers$Differ<-0.4681-Average_Volunteers$Avg
Average_Volunteers

#We find that 2 volunteers Ana Maria Agrusa (13) and Laninda Sande (154) have averages closest to the overall average (0.4615385), therefore we can use either volunteer in the model 
```


Create the background map on which the model predictions will be mapped 
```{r}
library("maps")
library("dplyr")
library("ggplot2")


states <- map_data("state")

se_map <- subset(states, region %in% c("florida", "georgia", "louisiana", "alabama", "mississippi", "texas", "south carolina", "oklahoma", "arkansas", "north carolina", "tennessee", "virginia", "kentucky", "west virginia", "missouri", "illinois", "kansas"))

```

We can now move on to creating a grid of predicted infection prevalence using the average observation values of volunteer #13.  
```{r}
data$Latitude<-as.numeric(data$Latitude)
data$Longitude<-as.numeric(data$Longitude)

se_map$Latitude<-as.numeric(se_map$lat)
se_map$Longitude<-as.numeric(se_map$long)

data$Year.Sampled<-as.factor(data$Year.Sampled)

#First we'll create gridded data

predict_infection = expand.grid(
  Latitude= seq(min(data$Latitude), 
                max(data$Latitude),
                length=100),
  Longitude = seq(min(data$Longitude),
                  max(data$Longitude),
                  length=100),
  Volunteer = levels(data$Volunteer)[13],  
  Year.Sampled = seq(2011,2018,by=1))

#head(predict_infection)

#summary(data)
```

Create the Model Fit Column 
```{r}

predict_infection$model_fit = predict(STyes,
                                    predict_infection,type = "response")

```

Create a for loop to build polygons for each group in the dataset 
```{r}
library(ggplot2)
library(viridis)
library(dplyr)

se_map<-se_map %>% mutate(Longitude=long,Latitude=lat)
predict_infection_clipped<-data.frame()
groups<-unique(se_map$group)

for(g in 1:length(groups))
{
  temp<-predict_infection[with(predict_infection %>% dplyr::select("Longitude","Latitude"), 
                               inSide(se_map %>% filter(group==groups[g]) %>% dplyr::select("Longitude","Latitude"),Longitude,Latitude)),]
  predict_infection_clipped<-rbind(predict_infection_clipped,temp)
  
}

library(mapproj)
library(maps)
library(ggrepel)

#Process for Making cities labels 
data(us.cities)
capitals <- subset(us.cities)
capitals$city <- sub(' [^ ]*$','',capitals$name) # split out city for the label

plotcities <- subset(world.cities, name %in% c("Atlanta", "Houston", "New Orleans", "Austin", "San Antonio", "Tampa", "Orlando", "Miami")) %>% filter(country.etc=="USA")


 
```

Graph the data
```{r}
gg<-ggplot(aes(Longitude, Latitude,  fill= model_fit), 
       data=predict_infection_clipped)+ #%>% filter(Year.Sampled==2011))+ 
  geom_tile()+
  facet_wrap(~Year.Sampled,nrow=4)+
  scale_fill_viridis("Infection Probability")+
  geom_polygon(data=se_map,aes(x=long,y=lat,group=group),color="black",inherit.aes = FALSE,alpha=0)+
  
  # geom_point(x = -84.42, y = 33.76, colour="red", size = 1)+
  # annotate(geom = "text", x = -84.42, y = 33.5, label = "Atlanta", 
  #   fontface = "bold", color = "white", size = 1)+
  # 
  # geom_point(x = -95.39, y = 29.77, colour="red", size = 1)+
  # annotate(geom = "text", x = -95.39, y = 29.5, label = "Houston", 
  #   fontface = "bold", color = "white", size = 1)+
  # 
  # geom_point(x = -89.93, y = 30.07, colour="red", size = 1)+
  # annotate(geom = "text", x = -88.00, y = 30.1, label = "New Orleans", 
  #   fontface = "bold", color = "white", size = 1)+
  # 
  # geom_point(x = -82.48, y = 27.96, colour="red", size = 1)+
  # annotate(geom = "text", x = -83.7, y = 27.88, label = "Tampa", 
  #   fontface = "bold", color = "white", size = 1)+

  coord_map(xlim = c(-98.5, -75),ylim = c(24, 37))

  g<-gg+ theme(panel.background = element_rect(fill = "skyblue3",
                                colour = "skyblue3"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())
g
  
save_plot("~/g.png", plot_tmp, base_height = NULL, base_aspect_ratio = 1.618, 
base_width = 6)

#library(OpenImageR)

#img<-OpenImageR::readImage("~/plot_tmp.png")
#imageShow(img)
 
```


Add space by day of year may be the next step in the analysis in order to see if infection changes in different regions through time
It seems like anytime I seem to know what I ma talking about she rears up 
We need to have a story with this. Especially from the spatiotemporal data. Think about story for publication 


Calculate the difference from year to year 
```{r}
predict_infection$model_change =predict(STyes,
                                      predict_infection%>%mutate(Year.Sampled=Year.Sampled+1),
                                      type = "response") - predict_infection$model_fit 



se_map<-se_map %>% mutate(Longitude=long,Latitude=lat)

predict_infection_clipped<-data.frame()
groups<-unique(se_map$group)

for(g in 1:length(groups))
{
  temp<-predict_infection[with(predict_infection %>% dplyr::select("Longitude","Latitude"), 
                               inSide(se_map %>% filter(group==groups[g]) %>% dplyr::select("Longitude","Latitude"),Longitude,Latitude)),]
  predict_infection_clipped<-rbind(predict_infection_clipped,temp)
  
}
```

```{r}

library(RColorBrewer)

summary(predict_infection_clipped)
#mimimum change = -0.71, max= 0.94

#Labels for each facet 


ggplot(aes(Longitude, Latitude, fill= model_change),
       data=predict_infection_clipped%>% filter(Year.Sampled < 2018))+
  geom_tile()+
  facet_wrap(~ (Year.Sampled = c("2011-2012", "2012-2013", "2013-2014", "2014-2015", "2015-2016", "2016-2017", "2017-2018")),nrow=2)
  #scale_fill_gradient2("Infection Probability", low = "green", high = "red", na.value = NA, limits = c(-1, 1),    breaks = c(-1, -0.5, 0, 0.5, 1),
   #labels = c(-1, -0.5, 0, 0.5, 1))





gg<-ggplot(aes(Longitude, Latitude,  fill= model_change), 
       data=predict_infection_clipped %>% filter(Year.Sampled < 2018))+ 
  geom_tile()+
  facet_wrap(~Year.Sampled,nrow=4)+
   scale_fill_gradient2("Rate of change\n(species per year)")+
  #scale_fill_drsimonj("Infection Probability", palette = "mixed", guide = "none")+
  geom_polygon(data=se_map,aes(x=long,y=lat,group=group),color="black",inherit.aes = FALSE,alpha=0)+ 
  theme_bw(10)+
  coord_map(xlim = c(-98.5, -75),ylim = c(24, 37))
  
  geom_point(x = -84.42, y = 33.76, colour="red", size = 2)+
  annotate(geom = "text", x = -84.42, y = 33.5, label = "Atlanta", 
    fontface = "bold", color = "white", size = 2)+
  
  geom_point(x = -95.39, y = 29.77, colour="red", size = 2)+
  annotate(geom = "text", x = -95.39, y = 29.5, label = "Houston", 
    fontface = "bold", color = "white", size = 2)+

  geom_point(x = -89.93, y = 30.07, colour="red", size = 2)+
  annotate(geom = "text", x = -88.00, y = 30.1, label = "New Orleans", 
    fontface = "bold", color = "white", size = 2)+
  
  geom_point(x = -82.48, y = 27.96, colour="red", size = 2)+
  annotate(geom = "text", x = -83.7, y = 27.88, label = "Tampa", 
    fontface = "bold", color = "white", size = 2)+

  

  gg+ theme(panel.background = element_rect(fill = "skyblue3",
                                colour = "skyblue3"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())
 gg     
```


Can we examine the relationship between season and location? 


```{r}


want <- seq(1, nrow(data), length.out = 200)
pdat <- with(data,
              data.frame(Day_Year = Day_Year[want], Year.Sampled = Year.Sampled[want],
                         Volunteer = Volunteer[want]))
 
 ## predict trend contributions
p  <- predict(gam_modII,  newdata = pdat, type = "terms", se.fit = TRUE)
p1 <- predict(m1$gam, newdata = pdat, type = "terms", se.fit = TRUE)
p2 <- predict(m2$gam, newdata = pdat, type = "terms", se.fit = TRUE)
p3 <- predict(m3$gam, newdata = pdat, type = "terms", se.fit = TRUE)

## combine with the predictions data, including fitted and SEs
pdat <- transform(pdat,
                   p  = p$fit[,2],  se  = p$se.fit[,2],
                   p1 = p1$fit[,2], se1 = p1$se.fit[,2],
                   p2 = p2$fit[,2], se2 = p2$se.fit[,2],
                   p3 = p3$fit[,2], se3 = p3$se.fit[,2])




op <- par(mar = c(5,4,2,2) + 0.1)
ylim <- with(pdat, range(p, p1, p2, p3))
> ylim[1] <- floor(ylim[1])
> ylim[2] <- ceiling(ylim[2])
> ylab <- expression(Temperature ~ (degree*C ~ centred))



plot(Infection - mean(Infection) ~ Day_Year, data = data, type = "n")
```





*Research Question 2*
How do the listed exogenous variables impact the spatial dynamics of OE infection prevalence change within year and between years in the sedentary population of monarch butterflies in the SE U.S.?
  
  1. Temperature  
  2. Precipitation 
  3. Monarch larval density 
  

*Environmental Variables Model* 
In the Brown et al. paper, they used the GAMs in the previous step to determine the end of season infection prevalence for each year. They then looked for "bivariate correlations" between these infection prevalences and different environmental variables. 

  *Examining the effect of freezing temperatures at 3 scales*
    1. How does the number of freezes per year impact the overall infection prevalence? 
    2. How does the number of freezes within each hardiness zone impact the overall infection prevalence?
    3. How does the number of freezes preceeding an observation impact infection? 
   
Creating a Weekly Infection MHD File
```{r}
library(readr)
MHD <- read_csv("C:/Users/CHS/Desktop/RFiles/MHD/MHD_5RFiles/MHD_AnalysesFiles/data/YR_MHD_weather_hardi2.csv")

#Create a data frame with infection, week, hardiness zone (or other geographic variable) and year 

 #Make sure date column is in correct format 
library(lubridate)
MHD$date<- parse_date_time(MHD$Date_Sampled, orders = c("mdy", "dmy","ymd"))
MHD$date<-as.Date(MHD$date)

  #Create the week variable 
MHD$week <- week(MHD$date)

  #Create new dataframe that averages infection by week, year, zone and ID of the weather station
weeklyMHD<-aggregate(Infection~week+zone+Station +Year, FUN=mean, data=MHD, na.rm=TRUE)

  #Create Year-Week Variable for Graphing 
weeklyMHD$YearWeek=paste(weeklyMHD$Year,"Week",weeklyMHD$week,sep="_")


  #Graph that Caz wanted 
library(ggplot2)
library(dplyr)
#weeklyMHD$Year<-as.factor(weeklyMHD$Year)
weeklyMHD %>%
filter(Year == "2016" ,zone == "10a") %>%
ggplot(aes(x=reorder(YearWeek, week), y=Infection)) + #Reorder by week so that there will be order 
geom_point(alpha = 0.3,  position = position_jitter()) + stat_smooth(method = "loess") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))



#Create dataframe with YearWeek Freezes 
weeklyMHD_all3 %>%
filter(Year == "2016" ,zone == "10a") %>%
```


Import Weather Data and Count Freezes per Week
```{r}
Weather_Hardi <- read_csv("C:/Users/CHS/Desktop/RFiles/MHD/MHD_5RFiles/MHD_AnalysesFiles/data/Weather_Hardi.csv")

#Turn each daily observation into a 0 or 1 for freezes, developmental 0 and then count the number of occurrences in a week. 


#Function for counting the number of freezes. Starting with identifying freeze days. 
freeze.days<-function (TMIN, Day){
  freeze.days<-c()
  for (i in 1:length(TMIN)){
    if(is.na(TMIN[i])){
      freezes<-NA
      }else if (TMIN[i]>0){
      freezes<-0
    }else{
      freezes<-1
    }
    freeze.days<-c(freeze.days, freezes)
  }
  return(freeze.days)
}

#and now the freeze day counter
Weather_Hardi$freeze.day<-freeze.days(Weather_Hardi$TMIN, Weather_Hardi$Day)

#Examine the number of freeze days to ensure a reasonable number have been recorded 
Weather_Hardi %>% group_by(freeze.day) %>% tally()

#Add the number of freezes in each week and add to weekly data frame 
  #Rename Columns to match MHD 
Weather_Hardi<-Weather_Hardi %>%
  rename(Year = Year.Sampled,
    Station = StationName)

 #Make sure date column is in correct format 
library(lubridate)
Weather_Hardi$date<- parse_date_time(Weather_Hardi$date, orders = c("mdy", "dmy","ymd"))
Weather_Hardi$date<-as.Date(Weather_Hardi$date)  

#Create the week variable 
Weather_Hardi$week <- week(Weather_Hardi$date)

#Add it up
FreezeDataFrame<-aggregate(freeze.day~week+zone+id +Year, FUN=sum, data=Weather_Hardi, na.rm=TRUE)

#Merge the freeze.day column into the weeklyMHD dataframe based on week, zone, station and year 
  #Put columns that are shared between dataframes int he same format
FreezeDataFrame$Year<-as.factor(FreezeDataFrame$Year)

weeklyMHD<-weeklyMHD %>%
  rename(id = Station)
  #Merge 
weeklyMHD_freeze<-left_join(weeklyMHD, FreezeDataFrame, by=c("week", "Year", "id"))

#Look at data to ensure accuracy 
weeklyMHD_freeze %>% group_by(zone.y) %>% tally()

```




Now add in TMIN to the weekly data by averaging the weekly TMIN 



```{r}
#Add it up
TMINDataFrame<-aggregate(TMIN~week+zone+id +Year, FUN=mean, data=Weather_Hardi, na.rm=TRUE)

#Merge the freeze.day column into the weeklyMHD dataframe based on week, zone, station and year 
  #Put columns that are shared between dataframes int he same format
TMINDataFrame$Year<-as.factor(TMINDataFrame$Year)

  #Merge 
weeklyMHD_freeze<-left_join(weeklyMHD_freeze, TMINDataFrame, by=c("week", "Year", "id"))

#Look at data to ensure accuracy 
weeklyMHD_freeze %>% group_by(Dev.Zero.days) %>% tally()
```



#To do next
Remove unneeeded olumns from weeklyMHD_freeze and save 
1. WHy is zone not the same? 
2. Models to test effects of different measures. 
3. Add a lag based on slow development time 



Ways to test lag 

```{r}


#Make sure variable names in each dataframe are in the same format and have the same name 
MHD<-MHD%>%
  rename(TMIN = TMIN2)

Weather_Hardi$date<- parse_date_time(Weather_Hardi$date, orders = c("mdy", "dmy","ymd"))
Weather_Hardi$date<-as.Date(Weather_Hardi$date)


library(zoo)
#JUst averages the previous 5 observations in the list of data 
LAG_WH = Weather_Hardi %>%
    dplyr::group_by(id, Year.Sampled) %>%
  dplyr::arrange(id, Year.Sampled, Day) %>%
  dplyr::mutate(temp.lag1 = lag(TMIN, n = 1)) %>%
  dplyr::mutate(temp.5.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 5, 
                                     FUN = mean, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))



```




Create Columns Asscoated with the Number of Freezes that have Occurred at 7, 30, 60 days 

```{r}
Weather_Hardi <- read_csv("C:/Users/CHS/Desktop/RFiles/MHD/MHD_5RFiles/MHD_AnalysesFiles/data/Weather_Hardi.csv")

#Turn each weather day into a 0 for no freeze or 1 for freeze 

#Function for counting the number of freezes. Starting with identifying freeze days. 
freeze.days<-function (TMIN, Day){
  freeze.days<-c()
  for (i in 1:length(TMIN)){
    if(is.na(TMIN[i])){
      freezes<-NA
      }else if (TMIN[i]>0){
      freezes<-0
    }else{
      freezes<-1
    }
    freeze.days<-c(freeze.days, freezes)
  }
  return(freeze.days)
}

#and now the freeze day counter
Weather_Hardi$freeze.day<-freeze.days(Weather_Hardi$TMIN, Weather_Hardi$Day)

#Examine the number of freeze days to ensure a reasonable number have been recorded 
Weather_Hardi %>% group_by(freeze.day) %>% tally()
```



```{r}
#############################################################
#Create the WEEKLY NUMBER OF FREEZES Infection Dataframe#
#############################################################
#Count the number of freezes in each week and add to weekly data frame 
  #Rename Columns to match MHD 
Weather_Hardi<-Weather_Hardi %>%
  rename(Year = Year.Sampled,
    Station = StationName)

 #Make sure date column is in correct format 
library(lubridate)
Weather_Hardi$date<- parse_date_time(Weather_Hardi$date, orders = c("mdy", "dmy","ymd"))
Weather_Hardi$date<-as.Date(Weather_Hardi$date)  

#Create the week variable 
Weather_Hardi$week <- week(Weather_Hardi$date)

#Add it up
FreezeDataFrame<-aggregate(freeze.day~week+zone+id +Year, FUN=sum, data=Weather_Hardi, na.rm=TRUE)

#Merge the freeze.day column into the weeklyMHD dataframe based on week, zone, station and year 
  #Put columns that are shared between dataframes int he same format
FreezeDataFrame$Year<-as.factor(FreezeDataFrame$Year)
weeklyMHD$Year<-as.factor(weeklyMHD$Year)


#Rename columns to prepare for the merge 
weeklyMHD<-weeklyMHD %>%
  rename(id = Station)
  #Merge 
weeklyMHD_freeze<-left_join(weeklyMHD, FreezeDataFrame, by=c("week", "Year", "id"))

#Look at data to ensure accuracy 
weeklyMHD_freeze %>% group_by(zone.y) %>% tally()

#############################################################
#Create the 30 DAY NUMBER OF FREEZES Infection Dataframe#
#############################################################
ThirtyDayMHD_freeze = Weather_Hardi %>%
    dplyr::group_by(id, Year) %>%
  dplyr::arrange(id, Year, Day) %>%
  dplyr::mutate(temp.lag1 = lag(freeze.day, n = 1)) %>%
  dplyr::mutate(temp.30.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 30, 
                                     FUN = sum, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))

#Check to ensure that there is a range of freezes 
ThirtyDayMHD_freeze %>% group_by(temp.30.previous) %>% tally()

#Remove unneeded columns prior to the merge 
ThirtyDayMHD_freeze = subset(ThirtyDayMHD_freeze, select = -c(Station, City, State, County, PostCode, latitude, longitude) )

#Prep column form 
ThirtyDayMHD_freeze$Year<-as.factor(ThirtyDayMHD_freeze$Year)


#Merge weekly infection dataframe with datapoints showing the number of freezes freeze data frame 
MHD30_freeze<-left_join(weeklyMHD, ThirtyDayMHD_freeze, by=c("week", "Year", "id"))

#############################################################
#Create the 60 DAY NUMBER OF FREEZES Infection Dataframe#
#############################################################
SixtyDayMHD_freeze = Weather_Hardi %>%
    dplyr::group_by(id, Year) %>%
  dplyr::arrange(id, Year, Day) %>%
  dplyr::mutate(temp.lag1 = lag(freeze.day, n = 1)) %>%
  dplyr::mutate(temp.60.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 60, 
                                     FUN = sum, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))

#Check to ensure that there is a range of freezes 
SixtyDayMHD_freeze %>% group_by(temp.60.previous) %>% tally()

#Remove unneeded columns prior to the merge 
SixtyDayMHD_freeze = subset(SixtyDayMHD_freeze, select = -c(freeze.day, temp.lag1,Station, City, State, County, PostCode, latitude, longitude) )

#Prep column form 
SixtyDayMHD_freeze$Year<-as.factor(SixtyDayMHD_freeze$Year)


#Merge weekly infection dataframe with datapoints showing the number of freezes freeze data frame 
MHD60_freeze<-left_join(weeklyMHD, SixtyDayMHD_freeze, by=c("week", "Year", "id"))
```








Create Columns Asscoated with DEVELOPMENTAL ZERO that have Occurred at 7, 30, 60 days 

```{r}

#Turn each weather day into a 0 for above developmental zero or 1 for below developmental zero  
dev.zero<-function (TMIN, Day){
  dev.zero<-c()
  for (i in 1:length(TMIN)){
    if(is.na(TMIN[i])){
      Dzero<-NA
      }else if (TMIN[i]>11){
      Dzero<-0
    }else{
      Dzero<-1
    }
    dev.zero<-c(dev.zero, Dzero)
  }
  return(dev.zero)
}


#and now the dev.zero day counter
Weather_Hardi$Dev.Zero.days<-dev.zero(Weather_Hardi$TMIN, Weather_Hardi$Day)

#Examine the number of freeze days to ensure a reasonable number have been recorded 
Weather_Hardi %>% group_by(Dev.Zero.days) %>% tally()


```



```{r}
#############################################################
#Create the WEEKLY NUMBER OF FREEZES Infection Dataframe#
#############################################################
#Count the number of dev.zero days in each week and add to weekly data frame 
DevZeroDataFrame<-aggregate(Dev.Zero.days~week+zone+id +Year, FUN=sum, data=Weather_Hardi, na.rm=TRUE)

#Merge the freeze.day column into the weeklyMHD dataframe based on week, zone, station and year 
  #Put columns that are shared between dataframes in the same format
DevZeroDataFrame$Year<-as.factor(DevZeroDataFrame$Year)
  #Merge 
weeklyMHD_devzero<-left_join(weeklyMHD, DevZeroDataFrame, by=c("week", "Year", "id"))

#Look at data to ensure accuracy 
weeklyMHD_all3 %>% group_by(Dev.Zero.days) %>% tally()


  
  plot(Infection~ Dev.Zero.days, data = weeklyMHD_all3)

#############################################################
#Create the 30 DAY NUMBER OF FREEZES Infection Dataframe#
#############################################################
ThirtyDayMHD_devzero = Weather_Hardi %>%
    dplyr::group_by(id, Year) %>%
  dplyr::arrange(id, Year, Day) %>%
  dplyr::mutate(temp.lag1 = lag(Dev.Zero.days, n = 1)) %>%
  dplyr::mutate(devzero.30.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 30, 
                                     FUN = sum, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))

#Check to ensure that there is a range of freezes 
ThirtyDayMHD_devzero %>% group_by(devzero.30.previous) %>% tally()

#Remove unneeded columns prior to the merge 
ThirtyDayMHD_devzero = subset(ThirtyDayMHD_devzero, select = -c(Station, City, State, County, PostCode, latitude, longitude) )

#Prep column form 
ThirtyDayMHD_devzero$Year<-as.factor(ThirtyDayMHD_devzero$Year)
MHD$Year<-as.factor(MHD$Year)

MHD$id<-MHD$Station



#Merge weekly infection dataframe with datapoints showing the number of freezes freeze data frame 
MHD30<-merge(MHD, ThirtyDayMHD_devzero, by=c("date", "id"))



library(data.table)
keys<-c("week", "Year", "id")
tData<-data.table(MHD, key = keys)
tBounce<-data.table(ThirtyDayMHD_devzero, key = keys)
tData[tBounce, devzero.30.previous := 1L]
tData %>% group_by(devzero.30.previous) %>% tally()


  plot(Infection~ devzero.30.previous, data = MHD30_freeze)

#############################################################
#Create the 60 DAY NUMBER OF FREEZES Infection Dataframe#
#############################################################
SixtyDayMHD_devzero = Weather_Hardi %>%
    dplyr::group_by(id, Year) %>%
  dplyr::arrange(id, Year, Day) %>%
  dplyr::mutate(temp.lag1 = lag(Dev.Zero.days, n = 1)) %>%
  dplyr::mutate(devzero.60.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 60, 
                                     FUN = sum, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))

#Check to ensure that there is a range of freezes 
SixtyDayMHD_devzero %>% group_by(devzero.60.previous) %>% tally()

#Remove unneeded columns prior to the merge 
SixtyDayMHD_devzero = subset(SixtyDayMHD_devzero, select = -c(freeze.day, temp.lag1,Station, City, State, County, PostCode, latitude, longitude) )

#Prep column form 
SixtyDayMHD_devzero$Year<-as.factor(SixtyDayMHD_devzero$Year)


#Merge weekly infection dataframe with datapoints showing the number of freezes freeze data frame 
MHD60_freeze<-left_join(MHD60_freeze, SixtyDayMHD_devzero, by=c("week", "Year", "id"))
```




Create Columns Asscoated with TMIN AVG that have Occurred at 7, 30, 60 days
```{r}
#############################################################
#Create the WEEKLY AVG OF TMIN Infection Dataframe#
#############################################################
#Count the number of dev.zero days in each week and add to weekly data frame 
TMINFrame<-aggregate(TMIN~week+zone+id +Year, FUN=mean, data=Weather_Hardi, na.rm=TRUE)

#Merge the freeze.day column into the weeklyMHD dataframe based on week, zone, station and year 
  #Put columns that are shared between dataframes in the same format
TMINFrame$Year<-as.factor(DevZeroDataFrame$Year)
  #Merge 
weeklyMHD_TMINavg<-left_join(weeklyMHD, TMINFrame, by=c("week", "Year", "id"))

#Look at data to ensure accuracy 
weeklyMHD_TMINavg %>% group_by(TMIN) %>% tally()

#############################################################
#Create the 30 DAY NUMBER OF FREEZES Infection Dataframe#
#############################################################
ThirtyDayMHD_TMIN = Weather_Hardi %>%
    dplyr::group_by(id, Year) %>%
  dplyr::arrange(id, Year, Day) %>%
  dplyr::mutate(temp.lag1 = lag(TMIN, n = 1)) %>%
  dplyr::mutate(TMIN.30.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 30, 
                                     FUN = mean, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))

#Check to ensure that there is a range of freezes 
ThirtyDayMHD_TMIN %>% group_by(TMIN.30.previous) %>% tally()

#Remove unneeded columns prior to the merge 
ThirtyDayMHD_TMIN = subset(ThirtyDayMHD_TMIN, select = -c(Station, City, State, County, PostCode, latitude, longitude) )

#Prep column form 
ThirtyDayMHD_TMIN$Year<-as.factor(ThirtyDayMHD_TMIN$Year)


#Merge weekly infection dataframe with datapoints showing the number of freezes freeze data frame 
MHD30_freeze<-left_join(MHD30_freeze, ThirtyDayMHD_TMIN, by=c("week", "Year", "id"))

#############################################################
#Create the 60 DAY NUMBER OF FREEZES Infection Dataframe#
#############################################################
SixtyDayMHD_TMIN = Weather_Hardi %>%
    dplyr::group_by(id, Year) %>%
  dplyr::arrange(id, Year, Day) %>%
  dplyr::mutate(temp.lag1 = lag(TMIN, n = 1)) %>%
  dplyr::mutate(TMIN.60.previous = zoo::rollapply(data = temp.lag1, 
                                     width = 60, 
                                     FUN = mean, 
                                     align = "right", 
                                     fill = NA, 
                                     na.rm = T))

#Check to ensure that there is a range of freezes 
SixtyDayMHD_TMIN %>% group_by(TMIN.60.previous) %>% tally()

#Remove unneeded columns prior to the merge 
SixtyDayMHD_TMIN = subset(SixtyDayMHD_TMIN, select = -c(freeze.day, temp.lag1,Station, City, State, County, PostCode, latitude, longitude) )

#Prep column form 
SixtyDayMHD_TMIN$Year<-as.factor(SixtyDayMHD_TMIN$Year)


#Merge weekly infection dataframe with datapoints showing the number of freezes freeze data frame 
MHD60_freeze<-left_join(MHD60_freeze, SixtyDayMHD_TMIN, by=c("week", "Year", "id"))
```


Writing and Merging The New DataFiles 
```{r}
write.csv(MHD30_freeze, "C:/Users/CHS/Desktop/RFiles/MHD/MHD_5RFiles/MHD_AnalysesFiles/data/MHD30Day.csv" )

write.csv(MHD60_freeze, "C:/Users/CHS/Desktop/RFiles/MHD/MHD_5RFiles/MHD_AnalysesFiles/data/MHD60Day.csv" )

weeklyMHD_all3<-left_join(weeklyMHD_TMINavg, weeklyMHD_freeze, by=c("week", "Year", "id"))
weeklyMHD_all3<-left_join(weeklyMHD_all3, weeklyMHD_devzero, by=c("week", "Year", "id"))
write.csv(weeklyMHD_all3, "C:/Users/CHS/Desktop/RFiles/MHD/MHD_5RFiles/MHD_AnalysesFiles/data/MHD7Day.csv" )





```



*Environmental Variable Models* 
Each of these GAM models includes 
```{r}
library(mgcv)


MHD30<-merge(MHD, ThirtyDayMHD_devzero, by=c("date", "id"))
MHD30$zone.x<-as.factor(MHD30$zone.x)

DZ30_gam <-mgcv:: gam(Infection ~ s(devzero.30.previous, k= 5) + Year + zone.x, data = MHD30_freeze)
summary(DZ30_gam)
plot(DZ30_gam)
AIC(DZ30_gam)

Z30_gam <-mgcv:: gam(Infection ~ s(devzero.30.previous, k= 5) + Year.x  , data = MHD30)
summary(Z30_gam)
plot(Z30_gam)
AIC(Z30_gam)

plot(Z30_gam, pages = 1,  trans = plogis,
     shift = coef(Z30_gam)[1], seWithMean = TRUE, rug = FALSE, shade = TRUE, shade.col = "lightgrey")

```







```{r}
#########################
#######TMIN Models#####
#########################
weeklyMHD_freeze$zone.x<-as.factor(weeklyMHD_freeze$zone.x)
weeklyMHD_freeze$zone<-as.numeric(weeklyMHD_freeze$zone.x)
library(gam)


TMIN7_gam <-mgcv:: gam(Infection ~ s(TMIN) + Year + zone.x, data = weeklyMHD_TMINavg)
TMIN8_gam <-mgcv:: gam(Infection ~ s(TMIN) + Year , data = weeklyMHD_TMINavg)

summary(TMIN7_gam)
plot(TMIN7_gam)
AIC(TMIN8_gam)

TMIN30_gam <-mgcv:: gam(Infection ~ s(TMIN.30.previous) + Year + zone.x, data = MHD30_freeze)
summary(TMIN30_gam)
plot(TMIN30_gam)
AIC(TMIN30_gam)


TMIN60_gam <-mgcv:: gam(Infection ~ s(TMIN.60.previous) + Year + zone.x, data = MHD60_freeze)
summary(TMIN60_gam)
plot(TMIN60_gam)
AIC(TMIN60_gam)


AIC
################################
###########Dev Zero#############
################################

DZ7_gam <-mgcv:: gam(Infection ~ s(Dev.Zero.days, k= 5) + Year + zone.x, data = weeklyMHD_all3)
summary(DZ7_gam)
plot(DZ7_gam)
AIC(DZ7_gam)


DZ30_gam <-mgcv:: gam(Infection ~ s(devzero.30.previous, k= 5) + Year + zone.x, data = MHD30_freeze)
summary(DZ30_gam)
plot(DZ30_gam)
AIC(DZ30_gam)


DZ60_gam <-mgcv:: gam(Infection ~ s(devzero.60.previous) + Year + zone.x, data = MHD60_freeze)
summary(DZ60_gam)
plot(DZ60_gam)
AIC(DZ60_gam)
DZ60_gam$aic


################################
###########Freezes#############
################################


F7_gam <-mgcv:: gam(Infection ~ s(freeze.day, k= 5) + Year + zone.x, data = weeklyMHD_all3)
summary(F7_gam)
plot(F7_gam)
F7_gam$aic

F30_gam <-mgcv:: gam(Infection ~ s(temp.30.previous, k= 5) + Year + zone.x, data = MHD30_freeze)
summary(F30_gam)
plot(F30_gam)
F30_gam$aic

F60_gam <-mgcv:: gam(Infection ~ s(temp.60.previous) + Year + zone.x, data = MHD60_freeze)
summary(F60_gam)
plot(F60_gam)
F60_gam$aic


gam_modTIME <- gam(Infection ~  s(Day_Year, bs = "cc") + s(Year.Sampled,  k = 8) + ti(Day_Year, bs = "cc", by = Year.Sampled, k= 8) + s(Volunteer, bs="re"), family = binomial, method = "REML", data = data)





plot(F7_gam, pages = 1,  trans = plogis,
     shift = coef(F7_gam)[1], seWithMean = TRUE, rug = FALSE, shade = TRUE, shade.col = "lightgrey")

save(Egam_mod0, file="Egam_mod0.Rdata")


summary(Egam_mod2)

```






weeklyMHD %>%
  filter(weeklyMHD$zone == "10a" & weeklyMHD$Year == "2014") %>%
ggplot(aes(x=YearWeek, y=Infection)) +
  geom_point(alpha = 0.3,  position = position_jitter()) + stat_smooth(method = "loess") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.25, hjust=0.25))




   
geom_vline(data = weeklyMHD, xintercept = (Week=="2015-01-01"))

```




*Checking the Model*
```{r}
gam.check(Egam_mod)

#gam.check does not seem to be the best method for visualizing logistic models

library(arm)

binnedplot(fitted(Egam_mod), 
           residuals(Egam_mod, type = "response"), 
           nclass = NULL, 
           xlab = "Expected Values", 
           ylab = "Average residual", 
           main = "S Year", 
           cex.pts = 0.8, 
           col.pts = 1, 
           col.int = "gray")

```



```{r}
plot(Egam_mod3, residuals=FALSE, pages = 1,  trans = plogis,
      seWithMean = TRUE, rug = FALSE, shade = TRUE, shade.col = "lightgrey")
```

```{r}
vis.gam(Egam_mod3, view=c("TMIN2","PRCP"),plot.type="contour", color = "terrain", contour.col = "black") 

```


